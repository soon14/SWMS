########## CHAT MODELS ##########
# OpenAI
langchain4j.chat-model.provider=openai
langchain4j.chat-model.openai.api-key=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
langchain4j.chat-model.openai.model-name=gpt-3.5-turbo
langchain4j.chat-model.openai.temperature=0.0
#langchain4j.chat-model.openai.top-p=1.0
#langchain4j.chat-model.openai.max-tokens=100
#langchain4j.chat-model.openai.presence-penalty=0.0
#langchain4j.chat-model.openai.frequency-penalty=0.0
langchain4j.chat-model.openai.timeout=PT20S
#langchain4j.chat-model.openai.max-retries=3
#langchain4j.chat-model.openai.log-requests=true
#langchain4j.chat-model.openai.log-responses=true
# HuggingFace
#langchain4j.chat-model.provider=huggingface
#langchain4j.chat-model.huggingface.access-token=hf_... you can generate it here: https://huggingface.co/settings/tokens
#langchain4j.chat-model.huggingface.model-id=tiiuae/falcon-7b-instruct
#langchain4j.chat-model.huggingface.timeout=PT10S
#langchain4j.chat-model.huggingface.temperature=0.1
#langchain4j.chat-model.huggingface.max-new-tokens=50
#langchain4j.chat-model.huggingface.return-full-text=false
#langchain4j.chat-model.huggingface.wait-for-model=true
# LocalAI
#langchain4j.chat-model.provider=localai
#langchain4j.chat-model.localai.base-url=http://localhost:8080
#langchain4j.chat-model.localai.model-name=orca-mini-3b.ggmlv3.q4_0.bin
#langchain4j.chat-model.localai.temperature=0.0
#langchain4j.chat-model.localai.top-p=1.0
#langchain4j.chat-model.localai.max-tokens=5
#langchain4j.chat-model.localai.timeout=PT60S
#langchain4j.chat-model.localai.max-retries=3
#langchain4j.chat-model.localai.log-requests=true
#langchain4j.chat-model.localai.log-responses=true
########## EMBEDDING MODELS ##########
# OpenAI
#langchain4j.embedding-model.provider=openai
#langchain4j.embedding-model.openai.api-key=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
##langchain4j.embedding-model.openai.model-name=text-embedding-ada-002
#langchain4j.embedding-model.openai.timeout=PT20S
##langchain4j.embedding-model.openai.max-retries=3
##langchain4j.embedding-model.openai.log-requests=true
##langchain4j.embedding-model.openai.log-responses=true
# HuggingFace
langchain4j.embedding-model.provider=huggingface
langchain4j.embedding-model.huggingface.access-token=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
langchain4j.embedding-model.huggingface.model-id=sentence-transformers/all-MiniLM-L6-v2
langchain4j.embedding-model.huggingface.timeout=PT10S
langchain4j.embedding-model.huggingface.wait-for-model=true
# LocalAI
#langchain4j.embedding-model.provider=localai
#langchain4j.embedding-model.localai.base-url=http://localhost:8080
#langchain4j.embedding-model.localai.model-name=bert
langchain4j.embedding-model.localai.timeout=PT60S
#langchain4j.embedding-model.localai.max-retries=3
#langchain4j.embedding-model.localai.log-requests=true
#langchain4j.embedding-model.localai.log-responses=true
########## MODERATION MODELS ##########
# OpenAI Moderation Model
#langchain4j.moderation-model.provider=openai
#langchain4j.moderation-model.openai.api-key=sk-... you can generate it here: https://platform.openai.com/account/api-keys
#langchain4j.moderation-model.openai.model-name=text-moderation-latest
langchain4j.moderation-model.openai.timeout=PT20S
#langchain4j.moderation-model.openai.log-requests=true
#langchain4j.moderation-model.openai.log-responses=true
########## LOGGING ##########
